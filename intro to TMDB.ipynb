{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc62eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tmdbsimple in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tmdbsimple) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tmdbsimple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda78a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-key'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/miran/.secret/tmdb_api.json') as f: #change the path to match YOUR path!!\n",
    "    login = json.load(f)\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcd1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c59f848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tmdbsimple.movies.Movies at 0x1fe1a1ff310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make a movie object using the .Movies function from tmdb\n",
    "movie = tmdb.Movies(603)\n",
    "\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b748cd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/giBJ0ezYNEobFBfB8H4JNTjmll.jpg',\n",
       " 'belongs_to_collection': {'id': 2344,\n",
       "  'name': 'The Matrix Collection',\n",
       "  'poster_path': '/bV9qTVHTVf0gkW0j7p7M0ILD4pG.jpg',\n",
       "  'backdrop_path': '/bRm2DEgUiYciDw3myHuYFInD7la.jpg'},\n",
       " 'budget': 63000000,\n",
       " 'genres': [{'id': 28, 'name': 'Action'},\n",
       "  {'id': 878, 'name': 'Science Fiction'}],\n",
       " 'homepage': 'http://www.warnerbros.com/matrix',\n",
       " 'id': 603,\n",
       " 'imdb_id': 'tt0133093',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Matrix',\n",
       " 'overview': 'Set in the 22nd century, The Matrix tells the story of a computer hacker who joins a group of underground insurgents fighting the vast and powerful computers who now rule the earth.',\n",
       " 'popularity': 98.799,\n",
       " 'poster_path': '/f89U3ADr1oiB1s9GkdPOEpXUk5H.jpg',\n",
       " 'production_companies': [{'id': 79,\n",
       "   'logo_path': '/tpFpsqbleCzEE2p5EgvUq6ozfCA.png',\n",
       "   'name': 'Village Roadshow Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 372,\n",
       "   'logo_path': None,\n",
       "   'name': 'Groucho II Film Partnership',\n",
       "   'origin_country': ''},\n",
       "  {'id': 1885,\n",
       "   'logo_path': '/xlvoOZr4s1PygosrwZyolIFe5xs.png',\n",
       "   'name': 'Silver Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 174,\n",
       "   'logo_path': '/IuAlhI9eVC9Z8UQWOIDdWRKSEJ.png',\n",
       "   'name': 'Warner Bros. Pictures',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '1999-03-30',\n",
       " 'revenue': 463517383,\n",
       " 'runtime': 136,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Welcome to the Real World.',\n",
       " 'title': 'The Matrix',\n",
       " 'video': False,\n",
       " 'vote_average': 8.2,\n",
       " 'vote_count': 24121}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## movie objects have a .info dictionary \n",
    "info = movie.info()\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e8d74",
   "metadata": {},
   "source": [
    "### There is a lot of information included here! You will see that budget and revenue are included in the .info(). However, if you look carefully, it does not include one of the things we will be looking for as part of our project which is the certification. Also, note that, for now, the last piece of information is 'vote_count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee08dab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94d81cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463517383"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db2fb6",
   "metadata": {},
   "source": [
    "### Notice that the .info() includes \"imbdb_id\" which we can use to match with our existing data frame of movies! You will recognize the \"tt\" numbers from IMDb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6fb268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tt0133093'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['imdb_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9b3c8",
   "metadata": {},
   "source": [
    "### Searching with IMDB_ID\n",
    "\n",
    "Try searching by the IMDb number. For example, What was the budget of Tom and Jerry which had an IMDb id of \"tt1361336\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da3ad781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = tmdb.Movies('tt1361336')\n",
    "info = movie.info()\n",
    "info['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc25420",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = movie.releases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878cd9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 587807,\n",
       " 'countries': [{'certification': 'PG',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'US',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-26'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'CO',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-12'},\n",
       "  {'certification': 'PG',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'US',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-26'},\n",
       "  {'certification': 'ALL',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'KR',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-24'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'ID',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-03-10'},\n",
       "  {'certification': '6',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'NL',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-09'},\n",
       "  {'certification': 'G',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'IE',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-07'},\n",
       "  {'certification': 'M/6',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'PT',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-03-04'},\n",
       "  {'certification': '6+',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'RU',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-25'},\n",
       "  {'certification': 'L',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'BR',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-11'},\n",
       "  {'certification': 'PG',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'GB',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-03-25'},\n",
       "  {'certification': '7',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'DK',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-11'},\n",
       "  {'certification': 'G',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'AU',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-04-01'},\n",
       "  {'certification': 'PG',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'GB',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-24'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'HK',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-03-11'},\n",
       "  {'certification': 'U',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'FR',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-19'},\n",
       "  {'certification': 'Btl',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'SE',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-28'},\n",
       "  {'certification': '0',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'DE',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-17'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'CZ',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-10'},\n",
       "  {'certification': 'G',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'AU',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-01'},\n",
       "  {'certification': 'G',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'NZ',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-01'},\n",
       "  {'certification': 'G',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'AU',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-21'},\n",
       "  {'certification': 'U',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'SK',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-27'},\n",
       "  {'certification': 'V',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'LT',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-07'},\n",
       "  {'certification': '6',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'HU',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-20'},\n",
       "  {'certification': 'PG',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'US',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-05-18'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'PL',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-11'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'CA',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-07-31'},\n",
       "  {'certification': '7',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'ES',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-03-26'},\n",
       "  {'certification': 'U',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'FR',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-09-16'},\n",
       "  {'certification': 'U',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'FR',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-09-22'},\n",
       "  {'certification': 'PG',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'SG',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-11'},\n",
       "  {'certification': 'U',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'FR',\n",
       "   'primary': False,\n",
       "   'release_date': '2022-02-16'},\n",
       "  {'certification': 'Κ',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'GR',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-06-10'},\n",
       "  {'certification': '普遍級',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'TW',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-10'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'GR',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-09-23'},\n",
       "  {'certification': '',\n",
       "   'descriptors': [],\n",
       "   'iso_3166_1': 'KZ',\n",
       "   'primary': False,\n",
       "   'release_date': '2021-02-25'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571cae5e",
   "metadata": {},
   "source": [
    "### Saving the movie Certification/MPAA Rating\n",
    "While MOST of the data we are interested in is stored in the .info(), the certification rating is not.\n",
    "\n",
    "The README for the package's repository shows how to obtain this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "188942cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG\n",
      "PG\n",
      "PG\n"
     ]
    }
   ],
   "source": [
    "# example from package README\n",
    "# source = https://github.com/celiao/tmdbsimple\n",
    "releases = movie.releases()\n",
    "for c in releases['countries']:\n",
    "    if c['iso_3166_1'] == 'US':\n",
    "        print(c['certification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25392d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movie object for the current id\n",
    "movie = tmdb.Movies('tt1361336')\n",
    "# save the .info .releases dictionaries\n",
    "info = movie.info()\n",
    "releases = movie.releases()\n",
    "# Loop through countries in releases\n",
    "for c in releases['countries']:\n",
    "    # if the country abbreviation==US\n",
    "    if c['iso_3166_1' ] =='US':\n",
    "        ## save a \"certification\" key in the info dict with the certification\n",
    "       info['certification'] = c['certification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a02e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Adapted from source + https://github.com/celiao/tmdbsimple\"\"\"\n",
    "    # Get the movie object for the current id\n",
    "    movie = tmdb.Movies('tt1361336')\n",
    "    # save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "    # if the country abbreviation==US\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "    ## save a \"certification\" key in the info dict with the certification\n",
    "            info['certification'] = c['certification']\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95b3d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id ='tt0848228'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f18ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/9ns9463dwOeo1CK1JU2wirL5Yi1.jpg',\n",
       " 'belongs_to_collection': None,\n",
       " 'budget': 50000000,\n",
       " 'genres': [{'id': 35, 'name': 'Comedy'},\n",
       "  {'id': 10751, 'name': 'Family'},\n",
       "  {'id': 16, 'name': 'Animation'}],\n",
       " 'homepage': 'https://www.tomandjerrymovie.com',\n",
       " 'id': 587807,\n",
       " 'imdb_id': 'tt1361336',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'Tom & Jerry',\n",
       " 'overview': 'Tom the cat and Jerry the mouse get kicked out of their home and relocate to a fancy New York hotel, where a scrappy employee named Kayla will lose her job if she can’t evict Jerry before a high-class wedding at the hotel. Her solution? Hiring Tom to get rid of the pesky mouse.',\n",
       " 'popularity': 56.481,\n",
       " 'poster_path': '/8XZI9QZ7Pm3fVkigWJPbrXCMzjq.jpg',\n",
       " 'production_companies': [{'id': 25120,\n",
       "   'logo_path': '/lMj6nMJBOzfLEd2fu8uF530AJcv.png',\n",
       "   'name': 'Warner Bros. Pictures Animation',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 8922,\n",
       "   'logo_path': '/yZWehAyjfKi4KvKeg1bkJ1bm5H8.png',\n",
       "   'name': 'Turner Entertainment',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 77061,\n",
       "   'logo_path': None,\n",
       "   'name': 'The Story Company',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 174,\n",
       "   'logo_path': '/IuAlhI9eVC9Z8UQWOIDdWRKSEJ.png',\n",
       "   'name': 'Warner Bros. Pictures',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2021-02-10',\n",
       " 'revenue': 136536687,\n",
       " 'runtime': 101,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Best of enemies. Worst of friends.',\n",
       " 'title': 'Tom & Jerry',\n",
       " 'video': False,\n",
       " 'vote_average': 6.843,\n",
       " 'vote_count': 2318,\n",
       " 'certification': 'PG'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_with_rating(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f917f652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/9ns9463dwOeo1CK1JU2wirL5Yi1.jpg',\n",
       " 'belongs_to_collection': None,\n",
       " 'budget': 50000000,\n",
       " 'genres': [{'id': 35, 'name': 'Comedy'},\n",
       "  {'id': 10751, 'name': 'Family'},\n",
       "  {'id': 16, 'name': 'Animation'}],\n",
       " 'homepage': 'https://www.tomandjerrymovie.com',\n",
       " 'id': 587807,\n",
       " 'imdb_id': 'tt1361336',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'Tom & Jerry',\n",
       " 'overview': 'Tom the cat and Jerry the mouse get kicked out of their home and relocate to a fancy New York hotel, where a scrappy employee named Kayla will lose her job if she can’t evict Jerry before a high-class wedding at the hotel. Her solution? Hiring Tom to get rid of the pesky mouse.',\n",
       " 'popularity': 56.481,\n",
       " 'poster_path': '/8XZI9QZ7Pm3fVkigWJPbrXCMzjq.jpg',\n",
       " 'production_companies': [{'id': 25120,\n",
       "   'logo_path': '/lMj6nMJBOzfLEd2fu8uF530AJcv.png',\n",
       "   'name': 'Warner Bros. Pictures Animation',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 8922,\n",
       "   'logo_path': '/yZWehAyjfKi4KvKeg1bkJ1bm5H8.png',\n",
       "   'name': 'Turner Entertainment',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 77061,\n",
       "   'logo_path': None,\n",
       "   'name': 'The Story Company',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 174,\n",
       "   'logo_path': '/IuAlhI9eVC9Z8UQWOIDdWRKSEJ.png',\n",
       "   'name': 'Warner Bros. Pictures',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2021-02-10',\n",
       " 'revenue': 136536687,\n",
       " 'runtime': 101,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Best of enemies. Worst of friends.',\n",
       " 'title': 'Tom & Jerry',\n",
       " 'video': False,\n",
       " 'vote_average': 6.843,\n",
       " 'vote_count': 2318,\n",
       " 'certification': 'PG'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = get_movie_with_rating(\"tt0848228\") #put your function name here\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6bb7df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, time, json\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "FOLDER = 'Data/'\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85176c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8824f1f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/title_basics.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load in the dataframe from project part 1 as basics:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m basics \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/title_basics.csv.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\common.py:750\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    748\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;66;03m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    751\u001b[0m             filename\u001b[38;5;241m=\u001b[39mhandle,\n\u001b[0;32m    752\u001b[0m             mode\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    753\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m         handle \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile(\n\u001b[0;32m    757\u001b[0m             \u001b[38;5;66;03m# No overload variant of \"GzipFile\" matches argument types\u001b[39;00m\n\u001b[0;32m    758\u001b[0m             \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    761\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[0;32m    762\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/title_basics.csv.gz'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load in the dataframe from project part 1 as basics:\n",
    "basics = pd.read_csv('Data/title_basics.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what do we need to do actually\n",
    "#1. API call for years\n",
    "\n",
    "YEARS_TO_GET = [2000,2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the JSON file to store results for year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa018a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fee4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "# save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72412f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving new year as the current df\n",
    "df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "# saving movie ids to list\n",
    "movie_ids = df['imdb id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing data from json into a dataframe called \"previous_df\"\n",
    "previous_df = pd.read_json(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce836081",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve then data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"- Total errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the JSON file to store results for year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "# Check if file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "# save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)\n",
    "        \n",
    "#Saving new year as the current df\n",
    "df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "# saving movie ids to list\n",
    "movie_ids = df['tconst'].copy()\n",
    "\n",
    "# Load existing data from json into a dataframe called \"previous_df\"\n",
    "previous_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                              desc=f'Movies from {YEAR}',\n",
    "                              position=1,\n",
    "                              leave=True):\n",
    "    try:\n",
    "        # Retrieve then data for the movie id\n",
    "        temp = get_movie_with_rating(movie_id)  \n",
    "        # Append/extend results to existing file using a pre-made function\n",
    "        write_json(temp,JSON_FILE)\n",
    "        # Short 20 ms sleep to prevent overwhelming server\n",
    "        time.sleep(0.02)\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append([movie_id, e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf934a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
