{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1193bb36",
   "metadata": {},
   "source": [
    "# Project 3 Part 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c5a98d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tmdbsimple in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tmdbsimple) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\miran\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests->tmdbsimple) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "# Install tmdbsimple (only need to run once)\n",
    "!pip install tmdbsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b51fe49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-key'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/miran/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "## Display the keys of the loaded dict\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34721956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84c911be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a movie object using the .Movies function from tmdb\n",
    "movie = tmdb.Movies(603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bedbf3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/giBJ0ezYNEobFBfB8H4JNTjmll.jpg',\n",
       " 'belongs_to_collection': {'id': 2344,\n",
       "  'name': 'The Matrix Collection',\n",
       "  'poster_path': '/bV9qTVHTVf0gkW0j7p7M0ILD4pG.jpg',\n",
       "  'backdrop_path': '/bRm2DEgUiYciDw3myHuYFInD7la.jpg'},\n",
       " 'budget': 63000000,\n",
       " 'genres': [{'id': 28, 'name': 'Action'},\n",
       "  {'id': 878, 'name': 'Science Fiction'}],\n",
       " 'homepage': 'http://www.warnerbros.com/matrix',\n",
       " 'id': 603,\n",
       " 'imdb_id': 'tt0133093',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Matrix',\n",
       " 'overview': 'Set in the 22nd century, The Matrix tells the story of a computer hacker who joins a group of underground insurgents fighting the vast and powerful computers who now rule the earth.',\n",
       " 'popularity': 93.22,\n",
       " 'poster_path': '/f89U3ADr1oiB1s9GkdPOEpXUk5H.jpg',\n",
       " 'production_companies': [{'id': 79,\n",
       "   'logo_path': '/tpFpsqbleCzEE2p5EgvUq6ozfCA.png',\n",
       "   'name': 'Village Roadshow Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 372,\n",
       "   'logo_path': None,\n",
       "   'name': 'Groucho II Film Partnership',\n",
       "   'origin_country': ''},\n",
       "  {'id': 1885,\n",
       "   'logo_path': '/xlvoOZr4s1PygosrwZyolIFe5xs.png',\n",
       "   'name': 'Silver Pictures',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 174,\n",
       "   'logo_path': '/IuAlhI9eVC9Z8UQWOIDdWRKSEJ.png',\n",
       "   'name': 'Warner Bros. Pictures',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '1999-03-30',\n",
       " 'revenue': 463517383,\n",
       " 'runtime': 136,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Welcome to the Real World.',\n",
       " 'title': 'The Matrix',\n",
       " 'video': False,\n",
       " 'vote_average': 8.208,\n",
       " 'vote_count': 24032}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## movie objects have a .info dictionary \n",
    "info = movie.info()\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c201a87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "# example from package README\n",
    "# source = https://github.com/celiao/tmdbsimple\n",
    "releases = movie.releases()\n",
    "for c in releases['countries']:\n",
    "    if c['iso_3166_1'] == 'US':\n",
    "        print(c['certification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6169d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movie object for the current id\n",
    "movie = tmdb.Movies('tt0848228')\n",
    "# save the .info .releases dictionaries\n",
    "info = movie.info()\n",
    "releases = movie.releases()\n",
    "# Loop through countries in releases\n",
    "for c in releases['countries']:\n",
    "    # if the country abbreviation==US\n",
    "    if c['iso_3166_1' ] =='US':\n",
    "        ## save a \"certification\" key in the info dict with the certification\n",
    "       info['certification'] = c['certification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89435aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "        # Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    # save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        # if the country abbreviation==US\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "            ## save a \"certification\" key in the info dict with the certification\n",
    "           info['certification'] = c['certification']\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b14f731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg',\n",
       " 'belongs_to_collection': {'id': 86311,\n",
       "  'name': 'The Avengers Collection',\n",
       "  'poster_path': '/yFSIUVTCvgYrpalUktulvk3Gi5Y.jpg',\n",
       "  'backdrop_path': '/zuW6fOiusv4X9nnW3paHGfXcSll.jpg'},\n",
       " 'budget': 220000000,\n",
       " 'genres': [{'id': 878, 'name': 'Science Fiction'},\n",
       "  {'id': 28, 'name': 'Action'},\n",
       "  {'id': 12, 'name': 'Adventure'}],\n",
       " 'homepage': 'https://www.marvel.com/movies/the-avengers',\n",
       " 'id': 24428,\n",
       " 'imdb_id': 'tt0848228',\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Avengers',\n",
       " 'overview': 'When an unexpected enemy emerges and threatens global safety and security, Nick Fury, director of the international peacekeeping agency known as S.H.I.E.L.D., finds himself in need of a team to pull the world back from the brink of disaster. Spanning the globe, a daring recruitment effort begins!',\n",
       " 'popularity': 133.545,\n",
       " 'poster_path': '/RYMX2wcKCBAr24UyPD7xwmjaTn.jpg',\n",
       " 'production_companies': [{'id': 420,\n",
       "   'logo_path': '/hUzeosd33nzE5MCNsZxCGEKTXaQ.png',\n",
       "   'name': 'Marvel Studios',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2012-04-25',\n",
       " 'revenue': 1518815515,\n",
       " 'runtime': 143,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'},\n",
       "  {'english_name': 'Hindi', 'iso_639_1': 'hi', 'name': 'हिन्दी'},\n",
       "  {'english_name': 'Russian', 'iso_639_1': 'ru', 'name': 'Pусский'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Some assembly required.',\n",
       " 'title': 'The Avengers',\n",
       " 'video': False,\n",
       " 'vote_average': 7.711,\n",
       " 'vote_count': 29295,\n",
       " 'certification': 'PG-13'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = get_movie_with_rating(\"tt0848228\") #put your function name here\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b710a",
   "metadata": {},
   "source": [
    "## Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc2e11e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'combined_tmdb_data.csv.gz',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'final_tmdb_data_2001.csv.gz',\n",
       " 'final_tmdb_data_2002.csv.gz',\n",
       " 'final_tmdb_data_2003.csv.gz',\n",
       " 'final_tmdb_data_2004.csv.gz',\n",
       " 'Title Basics.csv',\n",
       " 'Title Ratings.csv',\n",
       " 'title_akas.csv.gz',\n",
       " 'title_basics.csv.gz',\n",
       " 'title_ratings.csv.gz',\n",
       " 'TMDB API Results.csv',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'tmdb_api_results_2002.json',\n",
       " 'tmdb_api_results_2003.json',\n",
       " 'tmdb_api_results_2004.json',\n",
       " 'tmdb_api_results_2005.json',\n",
       " 'tmdb_results_combined.csv.gz']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, time, json\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "FOLDER = 'Data/'\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae109089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "083ef17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in csv.gz\n",
    "import pandas as pd\n",
    "basics = pd.read_csv('Data/title_basics.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69e06495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run years 2000-2004\n",
    "YEARS_TO_GET = [2005]\n",
    "#,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "607f3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7089ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78256473cf4469fa22e376a3d5c794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [56], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m movie_ids \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load existing data from json into a dataframe called \"previous_df\"\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m previous_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mJSON_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# filter out any ids that are already in the JSON_FILE\u001b[39;00m\n\u001b[0;32m     23\u001b[0m movie_ids_to_get \u001b[38;5;241m=\u001b[39m movie_ids[\u001b[38;5;241m~\u001b[39mmovie_ids\u001b[38;5;241m.\u001b[39misin(previous_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_id\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:757\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:915\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:937\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    935\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 937\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1064\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1321\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1317\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1321\u001b[0m         \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m     )\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1324\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1325\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1326\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1327\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    #Defining the JSON file to store results for year\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "    # Check if file exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "    # If it does not exist: create it\n",
    "    if file_exists == False:\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "\n",
    "    #Saving new year as the current df\n",
    "    df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "    # saving movie ids to list\n",
    "    movie_ids = df['imdb id'].copy()\n",
    "\n",
    "    # Load existing data from json into a dataframe called \"previous_df\"\n",
    "    previous_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "    # filter out any ids that are already in the JSON_FILE\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve then data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "\n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])\n",
    "            \n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c16fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
